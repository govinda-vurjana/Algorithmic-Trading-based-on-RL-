"""
Example Working Solution
========================
This shows a simple approach that should pass most requirements.
"""

def preprocess_data(filepath, target_column, test_size=0.2, random_state=42):
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.impute import SimpleImputer
    
    # Load and validate data
    df = pd.read_csv(filepath)
    
    if target_column not in df.columns:
        raise ValueError(f"Target column '{target_column}' not found")
    
    # Separate features and target
    X = df.drop(columns=[target_column])
    y = df[target_column]
    
    # Split FIRST to prevent data leakage
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # Handle missing values (avoid inplace warnings)
    numeric_cols = X_train.select_dtypes(include=[np.number]).columns
    categorical_cols = X_train.select_dtypes(include=['object']).columns
    
    # Impute numeric columns with median
    for col in numeric_cols:
        median_val = X_train[col].median()
        X_train[col] = X_train[col].fillna(median_val)
        X_test[col] = X_test[col].fillna(median_val)
    
    # Impute categorical columns with mode
    for col in categorical_cols:
        mode_val = X_train[col].mode()[0] if not X_train[col].mode().empty else 'missing'
        X_train[col] = X_train[col].fillna(mode_val)
        X_test[col] = X_test[col].fillna(mode_val)
    
    # One-hot encode categorical variables (use current sklearn API)
    X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)
    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)
    
    # Ensure both sets have the same columns
    missing_cols = set(X_train_encoded.columns) - set(X_test_encoded.columns)
    for col in missing_cols:
        X_test_encoded[col] = 0
    
    extra_cols = set(X_test_encoded.columns) - set(X_train_encoded.columns)
    for col in extra_cols:
        X_test_encoded = X_test_encoded.drop(columns=[col])
    
    X_test_encoded = X_test_encoded[X_train_encoded.columns]
    
    # Normalize numeric features (fit on train, transform both)
    scaler = StandardScaler()
    numeric_cols_encoded = X_train_encoded.select_dtypes(include=[np.number]).columns
    
    X_train_encoded[numeric_cols_encoded] = scaler.fit_transform(X_train_encoded[numeric_cols_encoded])
    X_test_encoded[numeric_cols_encoded] = scaler.transform(X_test_encoded[numeric_cols_encoded])
    
    return X_train_encoded, X_test_encoded, y_train, y_test